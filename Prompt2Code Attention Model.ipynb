{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyAjM4OwLIXp"
      },
      "source": [
        "# Conversational AI for Python Code Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlv7IfhFQhsv"
      },
      "source": [
        "### Fetching the Data and Loading the Required Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5He42w-lJcMZ",
        "outputId": "e28d5d8f-847f-487f-b95b-67826fa2dda1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-07-12 02:43:46--  https://drive.google.com/u/0/uc?id=1rHb0FQ5z5ZpaY2HpyFGY6CeyDG0kTLoO&export=download\n",
            "Resolving drive.google.com (drive.google.com)... 142.251.2.101, 142.251.2.139, 142.251.2.138, ...\n",
            "Connecting to drive.google.com (drive.google.com)|142.251.2.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://drive.google.com/uc?id=1rHb0FQ5z5ZpaY2HpyFGY6CeyDG0kTLoO&export=download [following]\n",
            "--2024-07-12 02:43:46--  https://drive.google.com/uc?id=1rHb0FQ5z5ZpaY2HpyFGY6CeyDG0kTLoO&export=download\n",
            "Reusing existing connection to drive.google.com:443.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=1rHb0FQ5z5ZpaY2HpyFGY6CeyDG0kTLoO&export=download [following]\n",
            "--2024-07-12 02:43:46--  https://drive.usercontent.google.com/download?id=1rHb0FQ5z5ZpaY2HpyFGY6CeyDG0kTLoO&export=download\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 142.251.2.132, 2607:f8b0:4023:c06::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|142.251.2.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1122316 (1.1M) [application/octet-stream]\n",
            "Saving to: ‘english_python_data.txt’\n",
            "\n",
            "english_python_data 100%[===================>]   1.07M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-07-12 02:43:49 (7.96 MB/s) - ‘english_python_data.txt’ saved [1122316/1122316]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget \"https://drive.google.com/u/0/uc?id=1rHb0FQ5z5ZpaY2HpyFGY6CeyDG0kTLoO&export=download\" -O english_python_data.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15IMBUHl1ICF"
      },
      "outputs": [],
      "source": [
        "!pip install torchtext==0.6.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-mOljzdcIZL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchtext\n",
        "from torchtext.data import Field, BucketIterator, Iterator\n",
        "from torchtext import data\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import spacy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import random\n",
        "import math\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YH5CgmwDF_G_"
      },
      "source": [
        "Checking for GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "5WZWgUq7N0Qn",
        "outputId": "e9cc6bc8-9e0a-4f52-8db7-ee96211f9a42"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0.6.0'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torchtext.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIwv64O6zIeU",
        "outputId": "d70c214c-3066-447e-98ff-a6b920a367c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: CUDA_LAUNCH_BLOCKING=1\n"
          ]
        }
      ],
      "source": [
        "%set_env CUDA_LAUNCH_BLOCKING = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1UTpnAaSUlp"
      },
      "source": [
        "<hr>\n",
        "\n",
        "### Reading the Text file comprising of Prompts and Codes\n",
        "\n",
        "- Every question starts with '#'.\n",
        "- Lines between two consecutive '#' forms the solution to the question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYRncG2sPvbS"
      },
      "outputs": [],
      "source": [
        "f = open(\"english_python_data.txt\", \"r\")\n",
        "file_lines = f.readlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcPoWVXRYqbT",
        "outputId": "be444689-fb33-4392-9787-f129f2cedc7c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['# write a python program to add two numbers \\n',\n",
              " 'num1 = 1.5\\n',\n",
              " 'num2 = 6.3\\n',\n",
              " 'sum = num1 + num2\\n',\n",
              " \"print(f'Sum: {sum}')\\n\",\n",
              " '\\n',\n",
              " '\\n',\n",
              " '# write a python function to add two user provided numbers and return the sum\\n',\n",
              " 'def add_two_numbers(num1, num2):\\n',\n",
              " '    sum = num1 + num2\\n',\n",
              " '    return sum\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '# write a program to find and print the largest among three numbers\\n',\n",
              " '\\n',\n",
              " 'num1 = 10\\n',\n",
              " 'num2 = 12\\n',\n",
              " 'num3 = 14\\n',\n",
              " 'if (num1 >= num2) and (num1 >= num3):\\n',\n",
              " '   largest = num1\\n']"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "file_lines[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1HR4YOwXXln"
      },
      "outputs": [],
      "source": [
        "dps = []\n",
        "dp = None\n",
        "for line in file_lines:\n",
        "  if line[0] == \"#\":\n",
        "    if dp:\n",
        "      dp['solution'] = ''.join(dp['solution'])\n",
        "      dps.append(dp)\n",
        "    dp = {\"question\": None, \"solution\": []}\n",
        "    dp['question'] = line[1:]\n",
        "  else:\n",
        "    dp[\"solution\"].append(line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qA-1MuOecZRt",
        "outputId": "fa730660-2450-43cd-e144-b3ef62960f18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset size: 4957\n"
          ]
        }
      ],
      "source": [
        "print(\"Dataset size:\", len(dps))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swBfwcDaXEh5"
      },
      "source": [
        "<hr>\n",
        "\n",
        "### Modifying existing Tokenizer and creating our custom tokenzier\n",
        "\n",
        "- This is because in Python, if we use default tokenizer, ```add_two_numbers``` might get tokenized to ```add```, ```two```, ```numbers```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_UsevXhPgh1R"
      },
      "outputs": [],
      "source": [
        "from tokenize import tokenize, untokenize\n",
        "import io\n",
        "\n",
        "\n",
        "def tokenize_python_code(python_code_str):\n",
        "    python_tokens = list(tokenize(io.BytesIO(python_code_str.encode('utf-8')).readline))\n",
        "    tokenized_output = []\n",
        "    for i in range(0, len(python_tokens)):\n",
        "        tokenized_output.append((python_tokens[i].type, python_tokens[i].string))\n",
        "    return tokenized_output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2V-sePckv1-K",
        "outputId": "8433507f-9700-4a34-bb76-39456686d655"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(63, 'utf-8'), (1, 'def'), (1, 'add_two_numbers'), (54, '('), (1, 'num1'), (54, ','), (1, 'num2'), (54, ')'), (54, ':'), (4, '\\n'), (5, '    '), (1, 'sum'), (54, '='), (1, 'num1'), (54, '+'), (1, 'num2'), (4, '\\n'), (1, 'return'), (1, 'sum'), (4, '\\n'), (62, '\\n'), (62, '\\n'), (6, ''), (0, '')]\n"
          ]
        }
      ],
      "source": [
        "tokenized_sample = tokenize_python_code(dps[1]['solution'])\n",
        "print(tokenized_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQ00a5cwwHtL",
        "outputId": "d1ec8b37-4f49-49d3-a106-d038550eb985"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "def add_two_numbers (num1 ,num2 ):\n",
            "    sum =num1 +num2 \n",
            "    return sum \n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(untokenize(tokenized_sample).decode('utf-8'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nsoc0eCpb8e"
      },
      "source": [
        "- Avoiding keyword literals ```(*keyword.kwlist*)```. We add all such literals that need to be skipped into the *skip_list*\n",
        "\n",
        "```skip_list = ['range', 'enumerate', 'print', 'ord', 'int', 'float', 'char', 'list', 'dict', 'tuple', 'set', 'len', 'sum', 'min', 'max']```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lM-tqDwhYoVJ",
        "outputId": "c3ab1239-c3dd-4bb4-815e-2f02520724a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['False', 'None', 'True', 'and', 'as', 'assert', 'async', 'await', 'break', 'class', 'continue', 'def', 'del', 'elif', 'else', 'except', 'finally', 'for', 'from', 'global', 'if', 'import', 'in', 'is', 'lambda', 'nonlocal', 'not', 'or', 'pass', 'raise', 'return', 'try', 'while', 'with', 'yield']\n"
          ]
        }
      ],
      "source": [
        "import keyword\n",
        "\n",
        "print(keyword.kwlist)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJkbFjjvHDDp"
      },
      "source": [
        "- Augmenting and Tokenizing to improve variety"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbIMyrYapfwS"
      },
      "outputs": [],
      "source": [
        "def augment_tokenize_python_code(python_code_str, mask_factor=0.3):\n",
        "\n",
        "\n",
        "    var_dict = {}\n",
        "    skip_list = ['range', 'enumerate', 'print', 'ord', 'int', 'float', 'zip'\n",
        "                 'char', 'list', 'dict', 'tuple', 'set', 'len', 'sum', 'min', 'max']\n",
        "    skip_list.extend(keyword.kwlist)\n",
        "\n",
        "    var_counter = 1\n",
        "    python_tokens = list(tokenize(io.BytesIO(python_code_str.encode('utf-8')).readline))\n",
        "    tokenized_output = []\n",
        "\n",
        "    for i in range(0, len(python_tokens)):\n",
        "      if python_tokens[i].type == 1 and python_tokens[i].string not in skip_list:\n",
        "\n",
        "        if i>0 and python_tokens[i-1].string in ['def', '.', 'import', 'raise', 'except', 'class']: # avoid masking modules, functions and error literals\n",
        "          skip_list.append(python_tokens[i].string)\n",
        "          tokenized_output.append((python_tokens[i].type, python_tokens[i].string))\n",
        "        elif python_tokens[i].string in var_dict:  # if variable is already masked\n",
        "          tokenized_output.append((python_tokens[i].type, var_dict[python_tokens[i].string]))\n",
        "        elif random.uniform(0, 1) > 1-mask_factor: # randomly mask variables\n",
        "          var_dict[python_tokens[i].string] = 'var_' + str(var_counter)\n",
        "          var_counter+=1\n",
        "          tokenized_output.append((python_tokens[i].type, var_dict[python_tokens[i].string]))\n",
        "        else:\n",
        "          skip_list.append(python_tokens[i].string)\n",
        "          tokenized_output.append((python_tokens[i].type, python_tokens[i].string))\n",
        "\n",
        "      else:\n",
        "        tokenized_output.append((python_tokens[i].type, python_tokens[i].string))\n",
        "\n",
        "    return tokenized_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shdWBNLu0DkK"
      },
      "source": [
        "<hr>\n",
        "\n",
        "### Building Train and Validation Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhBx_KFVaJIK"
      },
      "outputs": [],
      "source": [
        "python_problems_df = pd.DataFrame(dps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6i3TKNUoaWPC",
        "outputId": "9ae76f1e-a1f0-4806-e360-dc36e19dfa66"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"python_problems_df\",\n  \"rows\": 4957,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3434,\n        \"samples\": [\n          \" In[59]:\\n\",\n          \" write a python program to reverse user provided number \\n\",\n          \" generates key:value pair for each item \\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"solution\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3343,\n        \"samples\": [\n          \"\\nX = [[12,7],\\n    [4 ,5],\\n    [3 ,8]]\\n\\nresult = [[0,0,0],\\n         [0,0,0]]\\n\\n\",\n          \"\\nterms = 10\\n\\nresult = list(map(lambda x: 2 ** x, range(terms)))\\n\\nprint(\\\"The total terms are:\\\",terms)\\nfor i in range(terms):\\n   print(\\\"2 raised to power\\\",i,\\\"is\\\",result[i])\\n   \\n\\n   \\n\",\n          \"def add_string(str1):\\n  length = len(str1)\\n\\n  if length > 2:\\n    if str1[-3:] == 'ing':\\n      str1 += 'ly'\\n    else:\\n      str1 += 'ing'\\n\\n  return str1\\n\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "python_problems_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-1edeff6f-9f3d-4f03-b6bb-a1613c0aa8dd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>solution</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>write a python program to add two numbers \\n</td>\n",
              "      <td>num1 = 1.5\\nnum2 = 6.3\\nsum = num1 + num2\\npri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>write a python function to add two user provi...</td>\n",
              "      <td>def add_two_numbers(num1, num2):\\n    sum = nu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>write a program to find and print the largest...</td>\n",
              "      <td>\\nnum1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 &gt;=...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>write a program to find and print the smalles...</td>\n",
              "      <td>num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 &lt;= n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Write a python function to merge two given li...</td>\n",
              "      <td>def merge_lists(l1, l2):\\n    return l1 + l2\\n...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1edeff6f-9f3d-4f03-b6bb-a1613c0aa8dd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1edeff6f-9f3d-4f03-b6bb-a1613c0aa8dd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1edeff6f-9f3d-4f03-b6bb-a1613c0aa8dd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-802b0970-e905-4e53-8e35-a8226c83ec9f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-802b0970-e905-4e53-8e35-a8226c83ec9f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-802b0970-e905-4e53-8e35-a8226c83ec9f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                            question  \\\n",
              "0       write a python program to add two numbers \\n   \n",
              "1   write a python function to add two user provi...   \n",
              "2   write a program to find and print the largest...   \n",
              "3   write a program to find and print the smalles...   \n",
              "4   Write a python function to merge two given li...   \n",
              "\n",
              "                                            solution  \n",
              "0  num1 = 1.5\\nnum2 = 6.3\\nsum = num1 + num2\\npri...  \n",
              "1  def add_two_numbers(num1, num2):\\n    sum = nu...  \n",
              "2  \\nnum1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 >=...  \n",
              "3  num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 <= n...  \n",
              "4  def merge_lists(l1, l2):\\n    return l1 + l2\\n...  "
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "python_problems_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_93zNqfepxY",
        "outputId": "366e0b3f-4684-4d5e-ef0e-e11e1c3ac5c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4957, 2)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "python_problems_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cdHbscZsSJu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(0)\n",
        "msk = np.random.rand(len(python_problems_df)) < 0.85 # Splitting data into 85% train and 15% validation\n",
        "\n",
        "train_df = python_problems_df[msk]\n",
        "val_df = python_problems_df[~msk]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDtZSkLUu53D",
        "outputId": "d904c699-f4cc-4e67-87e4-611cd9a686a7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4211, 2)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3SkbK0Qu9TZ",
        "outputId": "9cfe89bd-8bcd-4d27-c81c-4be229162ccb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(746, 2)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6u7EyiRZ6brX"
      },
      "source": [
        "### Vocabulary generation using TorchText"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3ZQQWsWi4rn"
      },
      "source": [
        "- Sequence to Sequence (Seq2Seq) approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PlIi4zsLKwLE"
      },
      "outputs": [],
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMB8MgBeH4Ui"
      },
      "source": [
        "- ```en_core_web_sm``` : **SpaCy** pipeline with vocabulary from Web Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwP7Rw374W-o"
      },
      "outputs": [],
      "source": [
        "# !python -m spacy download en_core_web_sm\n",
        "\n",
        "spacy_en = spacy.load('en_core_web_sm')\n",
        "\n",
        "def tokenize_spacy(text):\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLID_2ZtixKY"
      },
      "outputs": [],
      "source": [
        "Input = data.Field(tokenize = tokenize_spacy,\n",
        "            init_token='<sos>',\n",
        "            eos_token='<eos>',\n",
        "            lower=True)\n",
        "\n",
        "Output = data.Field(tokenize = augment_tokenize_python_code,\n",
        "                    init_token='<sos>',\n",
        "                    eos_token='<eos>',\n",
        "                    lower=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttEpbc2rixPx"
      },
      "outputs": [],
      "source": [
        "fields = [('Input', Input),('Output', Output)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxsyNTBtogcD"
      },
      "source": [
        "- Capturing as many variations as possible in the vocabulary that we develop.\n",
        "- Applying our data augmentations 100 times to ensure that we can capture a majority of augmentations into our vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uP_yJeqjoLLV"
      },
      "outputs": [],
      "source": [
        "train_example = []\n",
        "val_example = []\n",
        "\n",
        "train_expansion_factor = 100\n",
        "for j in range(train_expansion_factor):\n",
        "  for i in range(train_df.shape[0]):\n",
        "      try:\n",
        "          ex = data.Example.fromlist([train_df.question[i], train_df.solution[i]], fields)\n",
        "          train_example.append(ex)\n",
        "      except:\n",
        "          pass\n",
        "\n",
        "for i in range(val_df.shape[0]):\n",
        "    try:\n",
        "        ex = data.Example.fromlist([val_df.question[i], val_df.solution[i]], fields)\n",
        "        val_example.append(ex)\n",
        "    except:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooT2EqpmtcAW"
      },
      "outputs": [],
      "source": [
        "train_data = data.Dataset(train_example, fields)\n",
        "valid_data =  data.Dataset(val_example, fields)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uk4zu6Ntqgfr"
      },
      "outputs": [],
      "source": [
        "Input.build_vocab(train_data, min_freq = 0)\n",
        "Output.build_vocab(train_data, min_freq = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oA17CYnDJa4D",
        "outputId": "df6e4d0f-fda5-41a5-b6ea-e32534e20804"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torchtext.vocab.Vocab at 0x7c1e8d68ded0>"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Output.vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fn7KGjMOIp2s"
      },
      "source": [
        "- Saving our generated vocabulary for future use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5f1HbzYuEcD"
      },
      "outputs": [],
      "source": [
        "def save_vocab(vocab, path):\n",
        "    import pickle\n",
        "    output = open(path, 'wb')\n",
        "    pickle.dump(vocab, output)\n",
        "    output.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lN6tUrOxuFac"
      },
      "outputs": [],
      "source": [
        "save_vocab(Input.vocab, \"/content/source_vocab.pkl\")\n",
        "save_vocab(Output.vocab, \"/content/target_vocab.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pv-5RpJuAjb",
        "outputId": "e1c21ecb-a809-42a1-aaf2-febc17a4328f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sZedgyzu7cD",
        "outputId": "c9e4327e-ec29-4492-c067-6b65fa881665"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Input': [' ', 'write', 'a', 'python', 'function', 'to', 'print', 'powers', 'of', '2', ',', 'for', 'given', 'number', 'of', 'terms'], 'Output': [(63, 'utf-8'), (1, 'def'), (1, 'two_power'), (54, '('), (1, 'var_1'), (54, ')'), (54, ':'), (4, '\\n'), (5, '    '), (1, 'result'), (54, '='), (1, 'list'), (54, '('), (1, 'map'), (54, '('), (1, 'lambda'), (1, 'x'), (54, ':'), (2, '2'), (54, '**'), (1, 'x'), (54, ','), (1, 'range'), (54, '('), (1, 'var_1'), (54, ')'), (54, ')'), (54, ')'), (4, '\\n'), (62, '\\n'), (1, 'print'), (54, '('), (3, 'f\"The total terms are: {terms}\"'), (54, ')'), (4, '\\n'), (1, 'for'), (1, 'i'), (1, 'in'), (1, 'range'), (54, '('), (1, 'var_1'), (54, ')'), (54, ':'), (4, '\\n'), (5, '       '), (1, 'print'), (54, '('), (3, 'f\"2^{i} = {result[i]}\"'), (54, ')'), (4, ''), (6, ''), (6, ''), (0, '')]}\n"
          ]
        }
      ],
      "source": [
        "print(vars(train_data.examples[8]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njS_msug6eQ3"
      },
      "source": [
        "<hr>\n",
        "\n",
        "### Transformer using Attention Mechanism"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSjhBKP59ntL"
      },
      "source": [
        "- Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NE6JimgOCz-w"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_dim,\n",
        "                 hid_dim,\n",
        "                 n_layers,\n",
        "                 n_heads,\n",
        "                 pf_dim,\n",
        "                 dropout,\n",
        "                 device,\n",
        "                 max_length = 1000):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "\n",
        "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "\n",
        "        self.layers = nn.ModuleList([EncoderLayer(hid_dim,\n",
        "                                                  n_heads,\n",
        "                                                  pf_dim,\n",
        "                                                  dropout,\n",
        "                                                  device)\n",
        "                                     for _ in range(n_layers)])\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        batch_size = src.shape[0]\n",
        "        src_len = src.shape[1]\n",
        "\n",
        "        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "        src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
        "        for layer in self.layers:\n",
        "            src = layer(src, src_mask)\n",
        "        return src"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1E12pQr9REU"
      },
      "source": [
        "- Encoder Layer within the Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LheiXWVFDEg"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self,\n",
        "                 hid_dim,\n",
        "                 n_heads,\n",
        "                 pf_dim,\n",
        "                 dropout,\n",
        "                 device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim,\n",
        "                                                                     pf_dim,\n",
        "                                                                     dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        #self attention\n",
        "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
        "\n",
        "        #dropout, residual connection and layer norm\n",
        "        src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
        "\n",
        "        #src = [batch size, src len, hid dim]\n",
        "\n",
        "        #positionwise feedforward\n",
        "        _src = self.positionwise_feedforward(src)\n",
        "\n",
        "        #dropout, residual and layer norm\n",
        "        src = self.ff_layer_norm(src + self.dropout(_src))\n",
        "\n",
        "        return src"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjEVmTzG9uZ4"
      },
      "source": [
        "- Feed Forward Neural Network (FFNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9w9xDUKL7LU"
      },
      "outputs": [],
      "source": [
        "class PositionwiseFeedforwardLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, pf_dim, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.fc_1 = nn.Linear(hid_dim, pf_dim)\n",
        "        self.fc_2 = nn.Linear(pf_dim, hid_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.dropout(torch.relu(self.fc_1(x)))\n",
        "\n",
        "        x = self.fc_2(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VroGxzNo-GGI"
      },
      "source": [
        "- Attention using **Query**, **Keys**, **Values**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZmeHfGhGzkN"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
        "        super().__init__()\n",
        "\n",
        "        assert hid_dim % n_heads == 0\n",
        "\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = hid_dim // n_heads\n",
        "\n",
        "        self.fc_q = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_k = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_v = nn.Linear(hid_dim, hid_dim)\n",
        "\n",
        "        self.fc_o = nn.Linear(hid_dim, hid_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "\n",
        "    def forward(self, query, key, value, mask = None):\n",
        "\n",
        "        batch_size = query.shape[0]\n",
        "        Q = self.fc_q(query)\n",
        "        K = self.fc_k(key)\n",
        "        V = self.fc_v(value)\n",
        "\n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "\n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
        "\n",
        "\n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == 0, -1e10)\n",
        "\n",
        "        attention = torch.softmax(energy, dim = -1)\n",
        "\n",
        "        x = torch.matmul(self.dropout(attention), V)\n",
        "\n",
        "        x = x.permute(0, 2, 1, 3).contiguous()\n",
        "\n",
        "        x = x.view(batch_size, -1, self.hid_dim)\n",
        "\n",
        "        x = self.fc_o(x)\n",
        "\n",
        "        return x, attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBFqGg5z-o_r"
      },
      "source": [
        "- Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWBMMF45MMNS"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 output_dim,\n",
        "                 hid_dim,\n",
        "                 n_layers,\n",
        "                 n_heads,\n",
        "                 pf_dim,\n",
        "                 dropout,\n",
        "                 device,\n",
        "                 max_length = 10000):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "\n",
        "        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "\n",
        "        self.layers = nn.ModuleList([DecoderLayer(hid_dim,\n",
        "                                                  n_heads,\n",
        "                                                  pf_dim,\n",
        "                                                  dropout,\n",
        "                                                  device)\n",
        "                                     for _ in range(n_layers)])\n",
        "\n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "\n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        batch_size = trg.shape[0]\n",
        "        trg_len = trg.shape[1]\n",
        "\n",
        "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "\n",
        "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
        "\n",
        "        for layer in self.layers:\n",
        "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
        "\n",
        "\n",
        "        output = self.fc_out(trg)\n",
        "\n",
        "        #output = [batch size, trg len, output dim]\n",
        "\n",
        "        return output, attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcK1-4qZ_WBM"
      },
      "source": [
        "- Single Decoder Layer within Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMEr1IFUMxco"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self,\n",
        "                 hid_dim,\n",
        "                 n_heads,\n",
        "                 pf_dim,\n",
        "                 dropout,\n",
        "                 device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.enc_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.encoder_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim,\n",
        "                                                                     pf_dim,\n",
        "                                                                     dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        #self attention\n",
        "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
        "\n",
        "        #dropout, residual connection and layer norm\n",
        "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
        "\n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "\n",
        "        #encoder attention\n",
        "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
        "        # query, key, value\n",
        "\n",
        "        #dropout, residual connection and layer norm\n",
        "        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
        "\n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "\n",
        "        #positionwise feedforward\n",
        "        _trg = self.positionwise_feedforward(trg)\n",
        "\n",
        "        #dropout, residual and layer norm\n",
        "        trg = self.ff_layer_norm(trg + self.dropout(_trg))\n",
        "\n",
        "        return trg, attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udpPhQ2UN8oQ"
      },
      "source": [
        "- Final Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dr3Mg8OGN6ul"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self,\n",
        "                 encoder,\n",
        "                 decoder,\n",
        "                 src_pad_idx,\n",
        "                 trg_pad_idx,\n",
        "                 device):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "        self.device = device\n",
        "\n",
        "    def make_src_mask(self, src):\n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "        return src_mask\n",
        "\n",
        "    def make_trg_mask(self, trg):\n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "        trg_len = trg.shape[1]\n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\n",
        "        return trg_mask\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        src_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.make_trg_mask(trg)\n",
        "        enc_src = self.encoder(src, src_mask)\n",
        "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
        "\n",
        "        return output, attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvrK6zbF_2Fs"
      },
      "source": [
        "<hr>\n",
        "\n",
        "### Model Training Set-Up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zsZjSSWOSHc"
      },
      "outputs": [],
      "source": [
        "INPUT_DIM = len(Input.vocab)\n",
        "OUTPUT_DIM = len(Output.vocab)\n",
        "HID_DIM = 256\n",
        "ENC_LAYERS = 3\n",
        "DEC_LAYERS = 3\n",
        "ENC_HEADS = 16\n",
        "DEC_HEADS = 16\n",
        "ENC_PF_DIM = 512\n",
        "DEC_PF_DIM = 512\n",
        "ENC_DROPOUT = 0.1\n",
        "DEC_DROPOUT = 0.1\n",
        "\n",
        "enc = Encoder(INPUT_DIM,\n",
        "              HID_DIM,\n",
        "              ENC_LAYERS,\n",
        "              ENC_HEADS,\n",
        "              ENC_PF_DIM,\n",
        "              ENC_DROPOUT,\n",
        "              device)\n",
        "\n",
        "dec = Decoder(OUTPUT_DIM,\n",
        "              HID_DIM,\n",
        "              DEC_LAYERS,\n",
        "              DEC_HEADS,\n",
        "              DEC_PF_DIM,\n",
        "              DEC_DROPOUT,\n",
        "              device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3vG-tI737e6",
        "outputId": "3b4f5222-3bbb-4067-a4ca-b1541209a452"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5666"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(Output.vocab.__dict__['freqs'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYVZYDVcOUGK"
      },
      "outputs": [],
      "source": [
        "SRC_PAD_IDX = Input.vocab.stoi[Input.pad_token]\n",
        "TRG_PAD_IDX = Output.vocab.stoi[Output.pad_token]\n",
        "\n",
        "model = Seq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qd0ePzj0OzLa",
        "outputId": "b42fe693-f637-4d6f-97c9-f324d5b8bc84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The model has 10,219,814 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmZ0hyo8O0vE"
      },
      "outputs": [],
      "source": [
        "def initialize_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRtAM9Y4O2N2"
      },
      "outputs": [],
      "source": [
        "model.apply(initialize_weights);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEpApG3YO3ZE"
      },
      "outputs": [],
      "source": [
        "LEARNING_RATE = 0.0005\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95cvaGRg_-Ml"
      },
      "source": [
        "<hr>\n",
        "\n",
        "### Designing loss function using Cross Entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNfxmsLxD7yb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CrossEntropyLoss(nn.CrossEntropyLoss):\n",
        "\n",
        "    def __init__(self, weight=None, ignore_index=-100, reduction='mean', smooth_eps=None, smooth_dist=None, from_logits=True):\n",
        "        super(CrossEntropyLoss, self).__init__(weight=weight,\n",
        "                                               ignore_index=ignore_index, reduction=reduction)\n",
        "        self.smooth_eps = smooth_eps\n",
        "        self.smooth_dist = smooth_dist\n",
        "        self.from_logits = from_logits\n",
        "\n",
        "    def forward(self, input, target, smooth_dist=None):\n",
        "        if smooth_dist is None:\n",
        "            smooth_dist = self.smooth_dist\n",
        "        return cross_entropy(input, target, weight=self.weight, ignore_index=self.ignore_index,\n",
        "                             reduction=self.reduction, smooth_eps=self.smooth_eps,\n",
        "                             smooth_dist=smooth_dist, from_logits=self.from_logits)\n",
        "\n",
        "\n",
        "def cross_entropy(inputs, target, weight=None, ignore_index=-100, reduction='mean',\n",
        "                  smooth_eps=None, smooth_dist=None, from_logits=True):\n",
        "    smooth_eps = smooth_eps or 0\n",
        "\n",
        "    if _is_long(target) and smooth_eps == 0:\n",
        "        if from_logits:\n",
        "            return F.cross_entropy(inputs, target, weight, ignore_index=ignore_index, reduction=reduction)\n",
        "        else:\n",
        "            return F.nll_loss(inputs, target, weight, ignore_index=ignore_index, reduction=reduction)\n",
        "\n",
        "    if from_logits:\n",
        "        lsm = F.log_softmax(inputs, dim=-1)\n",
        "    else:\n",
        "        lsm = inputs\n",
        "\n",
        "    masked_indices = None\n",
        "    num_classes = inputs.size(-1)\n",
        "\n",
        "    if _is_long(target) and ignore_index >= 0:\n",
        "        masked_indices = target.eq(ignore_index)\n",
        "\n",
        "    if smooth_eps > 0 and smooth_dist is not None:\n",
        "        if _is_long(target):\n",
        "            target = onehot(target, num_classes).type_as(inputs)\n",
        "        if smooth_dist.dim() < target.dim():\n",
        "            smooth_dist = smooth_dist.unsqueeze(0)\n",
        "        target.lerp_(smooth_dist, smooth_eps)\n",
        "\n",
        "    if weight is not None:\n",
        "        lsm = lsm * weight.unsqueeze(0)\n",
        "\n",
        "    if _is_long(target):\n",
        "        eps_sum = smooth_eps / num_classes\n",
        "        eps_nll = 1. - eps_sum - smooth_eps\n",
        "        likelihood = lsm.gather(dim=-1, index=target.unsqueeze(-1)).squeeze(-1)\n",
        "        loss = -(eps_nll * likelihood + eps_sum * lsm.sum(-1))\n",
        "    else:\n",
        "        loss = -(target * lsm).sum(-1)\n",
        "\n",
        "    if masked_indices is not None:\n",
        "        loss.masked_fill_(masked_indices, 0)\n",
        "\n",
        "    if reduction == 'sum':\n",
        "        loss = loss.sum()\n",
        "    elif reduction == 'mean':\n",
        "        if masked_indices is None:\n",
        "            loss = loss.mean()\n",
        "        else:\n",
        "            loss = loss.sum() / float(loss.size(0) - masked_indices.sum())\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "def onehot(indexes, N=None, ignore_index=None):\n",
        "    if N is None:\n",
        "        N = indexes.max() + 1\n",
        "    sz = list(indexes.size())\n",
        "    output = indexes.new().byte().resize_(*sz, N).zero_()\n",
        "    output.scatter_(-1, indexes.unsqueeze(-1), 1)\n",
        "    if ignore_index is not None and ignore_index >= 0:\n",
        "        output.masked_fill_(indexes.eq(ignore_index).unsqueeze(-1), 0)\n",
        "    return output\n",
        "\n",
        "def _is_long(x):\n",
        "    if hasattr(x, 'data'):\n",
        "        x = x.data\n",
        "    return isinstance(x, torch.LongTensor) or isinstance(x, torch.cuda.LongTensor)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnWtafKlAhb_"
      },
      "outputs": [],
      "source": [
        "def maskNLLLoss(inp, target, mask):\n",
        "    nTotal = mask.sum()\n",
        "    crossEntropy = CrossEntropyLoss(ignore_index = TRG_PAD_IDX, smooth_eps=0.20)\n",
        "    loss = crossEntropy(inp, target)\n",
        "    loss = loss.to(device)\n",
        "    return loss, nTotal.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9Dy_wWrO46l"
      },
      "outputs": [],
      "source": [
        "criterion = maskNLLLoss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQGdcEFmAxlO"
      },
      "source": [
        "<hr>\n",
        "\n",
        "### Seq2Seq Model Training\n",
        "\n",
        "- To apply augmentations differently in every epoch, re-create our dataset and dataloaders at the start of each epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ycBBiEpuO6cG"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def make_trg_mask(trg):\n",
        "        trg_pad_mask = (trg != TRG_PAD_IDX).unsqueeze(1).unsqueeze(2)\n",
        "        trg_len = trg.shape[1]\n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = device)).bool()\n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\n",
        "        return trg_mask\n",
        "\n",
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    n_totals = 0\n",
        "    print_losses = []\n",
        "    for i, batch in tqdm(enumerate(iterator), total=len(iterator)):\n",
        "        loss = 0\n",
        "        src = batch.Input.permute(1, 0)\n",
        "        trg = batch.Output.permute(1, 0)\n",
        "        trg_mask = make_trg_mask(trg)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output, _ = model(src, trg[:,:-1])\n",
        "        output_dim = output.shape[-1]\n",
        "\n",
        "        output = output.contiguous().view(-1, output_dim)\n",
        "        trg = trg[:,1:].contiguous().view(-1)\n",
        "        mask_loss, nTotal = criterion(output, trg, trg_mask)\n",
        "\n",
        "        mask_loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        print_losses.append(mask_loss.item() * nTotal)\n",
        "        n_totals += nTotal\n",
        "\n",
        "    return sum(print_losses) / n_totals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zi3Ev8gaO79_"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    n_totals = 0\n",
        "    print_losses = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for i, batch in tqdm(enumerate(iterator), total=len(iterator)):\n",
        "\n",
        "            src = batch.Input.permute(1, 0)\n",
        "            trg = batch.Output.permute(1, 0)\n",
        "            trg_mask = make_trg_mask(trg)\n",
        "\n",
        "            output, _ = model(src, trg[:,:-1])\n",
        "            output_dim = output.shape[-1]\n",
        "\n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            trg = trg[:,1:].contiguous().view(-1)\n",
        "\n",
        "            mask_loss, nTotal = criterion(output, trg, trg_mask)\n",
        "\n",
        "            print_losses.append(mask_loss.item() * nTotal)\n",
        "            n_totals += nTotal\n",
        "\n",
        "    return sum(print_losses) / n_totals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JuB4JqQRO9Wg"
      },
      "outputs": [],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aax76Ie4O_Cr",
        "outputId": "5e6db1b1-c67a-4971-b657-11c2b4da83ff"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.24it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 50.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 0m 20s\n",
            "\tTrain Loss: 5.021 | Train PPL: 151.594\n",
            "\t Val. Loss: 4.346 |  Val. PPL:  77.134\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:17<00:00, 12.70it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 51.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 02 | Time: 0m 18s\n",
            "\tTrain Loss: 4.188 | Train PPL:  65.885\n",
            "\t Val. Loss: 4.165 |  Val. PPL:  64.386\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:16<00:00, 13.34it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 51.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 03 | Time: 0m 17s\n",
            "\tTrain Loss: 3.965 | Train PPL:  52.725\n",
            "\t Val. Loss: 3.966 |  Val. PPL:  52.769\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:15<00:00, 13.91it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 50.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 04 | Time: 0m 17s\n",
            "\tTrain Loss: 3.805 | Train PPL:  44.946\n",
            "\t Val. Loss: 3.867 |  Val. PPL:  47.805\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:15<00:00, 13.93it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 47.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 05 | Time: 0m 17s\n",
            "\tTrain Loss: 3.687 | Train PPL:  39.910\n",
            "\t Val. Loss: 3.820 |  Val. PPL:  45.608\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:16<00:00, 13.77it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 49.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 06 | Time: 0m 17s\n",
            "\tTrain Loss: 3.580 | Train PPL:  35.870\n",
            "\t Val. Loss: 3.769 |  Val. PPL:  43.348\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:15<00:00, 13.91it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 51.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 07 | Time: 0m 17s\n",
            "\tTrain Loss: 3.486 | Train PPL:  32.648\n",
            "\t Val. Loss: 3.715 |  Val. PPL:  41.043\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:16<00:00, 13.57it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 49.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 08 | Time: 0m 17s\n",
            "\tTrain Loss: 3.404 | Train PPL:  30.088\n",
            "\t Val. Loss: 3.683 |  Val. PPL:  39.756\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:16<00:00, 13.77it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 51.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 09 | Time: 0m 17s\n",
            "\tTrain Loss: 3.332 | Train PPL:  28.002\n",
            "\t Val. Loss: 3.638 |  Val. PPL:  37.999\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:16<00:00, 13.70it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 35.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 10 | Time: 0m 17s\n",
            "\tTrain Loss: 3.268 | Train PPL:  26.269\n",
            "\t Val. Loss: 3.630 |  Val. PPL:  37.729\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:16<00:00, 13.63it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 49.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 11 | Time: 0m 20s\n",
            "\tTrain Loss: 3.213 | Train PPL:  24.843\n",
            "\t Val. Loss: 3.614 |  Val. PPL:  37.131\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:16<00:00, 13.80it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 50.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 12 | Time: 0m 17s\n",
            "\tTrain Loss: 3.164 | Train PPL:  23.665\n",
            "\t Val. Loss: 3.581 |  Val. PPL:  35.910\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:16<00:00, 13.51it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 50.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 13 | Time: 0m 18s\n",
            "\tTrain Loss: 3.114 | Train PPL:  22.521\n",
            "\t Val. Loss: 3.544 |  Val. PPL:  34.591\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:16<00:00, 13.85it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 52.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 14 | Time: 0m 17s\n",
            "\tTrain Loss: 3.069 | Train PPL:  21.510\n",
            "\t Val. Loss: 3.566 |  Val. PPL:  35.372\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:16<00:00, 13.63it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 51.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 15 | Time: 0m 17s\n",
            "\tTrain Loss: 3.034 | Train PPL:  20.774\n",
            "\t Val. Loss: 3.546 |  Val. PPL:  34.668\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:15<00:00, 13.88it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 49.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 16 | Time: 0m 17s\n",
            "\tTrain Loss: 2.997 | Train PPL:  20.034\n",
            "\t Val. Loss: 3.529 |  Val. PPL:  34.107\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:15<00:00, 13.91it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 48.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 17 | Time: 0m 17s\n",
            "\tTrain Loss: 2.972 | Train PPL:  19.527\n",
            "\t Val. Loss: 3.515 |  Val. PPL:  33.619\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:16<00:00, 13.78it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 52.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 18 | Time: 0m 18s\n",
            "\tTrain Loss: 2.945 | Train PPL:  19.003\n",
            "\t Val. Loss: 3.522 |  Val. PPL:  33.844\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:16<00:00, 13.81it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 52.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 19 | Time: 0m 17s\n",
            "\tTrain Loss: 2.917 | Train PPL:  18.485\n",
            "\t Val. Loss: 3.536 |  Val. PPL:  34.314\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:17<00:00, 13.04it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 42.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 20 | Time: 0m 18s\n",
            "\tTrain Loss: 2.899 | Train PPL:  18.156\n",
            "\t Val. Loss: 3.543 |  Val. PPL:  34.554\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:16<00:00, 13.77it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 51.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 21 | Time: 0m 17s\n",
            "\tTrain Loss: 2.877 | Train PPL:  17.756\n",
            "\t Val. Loss: 3.508 |  Val. PPL:  33.392\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:16<00:00, 13.87it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 50.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 22 | Time: 0m 17s\n",
            "\tTrain Loss: 2.858 | Train PPL:  17.421\n",
            "\t Val. Loss: 3.497 |  Val. PPL:  33.033\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:16<00:00, 13.56it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 51.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 23 | Time: 0m 18s\n",
            "\tTrain Loss: 2.841 | Train PPL:  17.132\n",
            "\t Val. Loss: 3.466 |  Val. PPL:  32.003\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:15<00:00, 13.90it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 48.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 24 | Time: 0m 17s\n",
            "\tTrain Loss: 2.822 | Train PPL:  16.814\n",
            "\t Val. Loss: 3.485 |  Val. PPL:  32.627\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:16<00:00, 13.47it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 51.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 25 | Time: 0m 17s\n",
            "\tTrain Loss: 2.804 | Train PPL:  16.506\n",
            "\t Val. Loss: 3.493 |  Val. PPL:  32.886\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:16<00:00, 13.76it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 48.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 26 | Time: 0m 17s\n",
            "\tTrain Loss: 2.793 | Train PPL:  16.325\n",
            "\t Val. Loss: 3.471 |  Val. PPL:  32.180\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:15<00:00, 13.89it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 52.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 27 | Time: 0m 17s\n",
            "\tTrain Loss: 2.780 | Train PPL:  16.123\n",
            "\t Val. Loss: 3.481 |  Val. PPL:  32.495\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:16<00:00, 13.71it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 51.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 28 | Time: 0m 18s\n",
            "\tTrain Loss: 2.765 | Train PPL:  15.873\n",
            "\t Val. Loss: 3.458 |  Val. PPL:  31.761\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:16<00:00, 13.84it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 52.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 29 | Time: 0m 17s\n",
            "\tTrain Loss: 2.754 | Train PPL:  15.709\n",
            "\t Val. Loss: 3.503 |  Val. PPL:  33.203\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:16<00:00, 13.17it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 50.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 30 | Time: 0m 18s\n",
            "\tTrain Loss: 2.746 | Train PPL:  15.587\n",
            "\t Val. Loss: 3.479 |  Val. PPL:  32.428\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:16<00:00, 13.69it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 52.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 31 | Time: 0m 17s\n",
            "\tTrain Loss: 2.729 | Train PPL:  15.321\n",
            "\t Val. Loss: 3.455 |  Val. PPL:  31.663\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:16<00:00, 13.66it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 40.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 32 | Time: 0m 17s\n",
            "\tTrain Loss: 2.729 | Train PPL:  15.325\n",
            "\t Val. Loss: 3.451 |  Val. PPL:  31.545\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:16<00:00, 13.78it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 47.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 33 | Time: 0m 17s\n",
            "\tTrain Loss: 2.707 | Train PPL:  14.986\n",
            "\t Val. Loss: 3.505 |  Val. PPL:  33.282\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:16<00:00, 13.87it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 51.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 34 | Time: 0m 17s\n",
            "\tTrain Loss: 2.705 | Train PPL:  14.952\n",
            "\t Val. Loss: 3.469 |  Val. PPL:  32.101\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:16<00:00, 13.77it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 51.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 35 | Time: 0m 17s\n",
            "\tTrain Loss: 2.689 | Train PPL:  14.720\n",
            "\t Val. Loss: 3.493 |  Val. PPL:  32.889\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:15<00:00, 13.88it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 49.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 36 | Time: 0m 18s\n",
            "\tTrain Loss: 2.682 | Train PPL:  14.610\n",
            "\t Val. Loss: 3.496 |  Val. PPL:  32.972\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:16<00:00, 13.54it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 45.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 37 | Time: 0m 17s\n",
            "\tTrain Loss: 2.680 | Train PPL:  14.588\n",
            "\t Val. Loss: 3.473 |  Val. PPL:  32.248\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:16<00:00, 13.87it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 51.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 38 | Time: 0m 17s\n",
            "\tTrain Loss: 2.668 | Train PPL:  14.410\n",
            "\t Val. Loss: 3.475 |  Val. PPL:  32.304\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:16<00:00, 13.78it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 38.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 39 | Time: 0m 17s\n",
            "\tTrain Loss: 2.662 | Train PPL:  14.324\n",
            "\t Val. Loss: 3.470 |  Val. PPL:  32.150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:16<00:00, 13.08it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 51.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 40 | Time: 0m 18s\n",
            "\tTrain Loss: 2.659 | Train PPL:  14.287\n",
            "\t Val. Loss: 3.460 |  Val. PPL:  31.827\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:16<00:00, 13.70it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 50.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 41 | Time: 0m 17s\n",
            "\tTrain Loss: 2.651 | Train PPL:  14.166\n",
            "\t Val. Loss: 3.470 |  Val. PPL:  32.150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:16<00:00, 13.15it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 51.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 42 | Time: 0m 18s\n",
            "\tTrain Loss: 2.640 | Train PPL:  14.017\n",
            "\t Val. Loss: 3.483 |  Val. PPL:  32.560\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:16<00:00, 13.66it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 49.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 43 | Time: 0m 17s\n",
            "\tTrain Loss: 2.638 | Train PPL:  13.983\n",
            "\t Val. Loss: 3.491 |  Val. PPL:  32.822\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:16<00:00, 13.12it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 50.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 44 | Time: 0m 18s\n",
            "\tTrain Loss: 2.631 | Train PPL:  13.893\n",
            "\t Val. Loss: 3.479 |  Val. PPL:  32.425\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:16<00:00, 13.63it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 49.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 45 | Time: 0m 17s\n",
            "\tTrain Loss: 2.622 | Train PPL:  13.769\n",
            "\t Val. Loss: 3.467 |  Val. PPL:  32.045\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:16<00:00, 13.63it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 43.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 46 | Time: 0m 17s\n",
            "\tTrain Loss: 2.621 | Train PPL:  13.745\n",
            "\t Val. Loss: 3.466 |  Val. PPL:  32.024\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:16<00:00, 13.51it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 49.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 47 | Time: 0m 18s\n",
            "\tTrain Loss: 2.620 | Train PPL:  13.729\n",
            "\t Val. Loss: 3.470 |  Val. PPL:  32.146\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:16<00:00, 13.68it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 48.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 48 | Time: 0m 17s\n",
            "\tTrain Loss: 2.611 | Train PPL:  13.607\n",
            "\t Val. Loss: 3.462 |  Val. PPL:  31.882\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:16<00:00, 13.25it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 50.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 49 | Time: 0m 18s\n",
            "\tTrain Loss: 2.603 | Train PPL:  13.506\n",
            "\t Val. Loss: 3.470 |  Val. PPL:  32.123\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:16<00:00, 13.13it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 48.05it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 50 | Time: 0m 18s\n",
            "\tTrain Loss: 2.604 | Train PPL:  13.515\n",
            "\t Val. Loss: 3.471 |  Val. PPL:  32.183\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "N_EPOCHS = 50\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_example = []\n",
        "    val_example = []\n",
        "\n",
        "    for i in range(train_df.shape[0]):\n",
        "        try:\n",
        "            ex = data.Example.fromlist([train_df.question[i], train_df.solution[i]], fields)\n",
        "            train_example.append(ex)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    for i in range(val_df.shape[0]):\n",
        "        try:\n",
        "            ex = data.Example.fromlist([val_df.question[i], val_df.solution[i]], fields)\n",
        "            val_example.append(ex)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    train_data = data.Dataset(train_example, fields)\n",
        "    valid_data =  data.Dataset(val_example, fields)\n",
        "\n",
        "    BATCH_SIZE = 16\n",
        "    train_iterator, valid_iterator = BucketIterator.splits((train_data, valid_data), batch_size = BATCH_SIZE,\n",
        "                                                                sort_key = lambda x: len(x.Input),\n",
        "                                                                sort_within_batch=True, device = device)\n",
        "\n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), '/content/conversational-ai-model.pt')\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMKkB13yPeJ7"
      },
      "outputs": [],
      "source": [
        "SRC = Input\n",
        "TRG = Output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTjI15dUKHzU"
      },
      "source": [
        "<hr>\n",
        "\n",
        "### Testing our trained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3_aq7QTPBFc",
        "outputId": "1d0df4f6-86c2-4430-98e1-8ba76a76e13f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('/content/conversational-ai-model.pt'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVCcGZjoKKjs"
      },
      "source": [
        "- The user prompt needs to be encoded and converted into **PyTorch Tensors** in order to be accepted by our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ieIjql9uPKH1"
      },
      "outputs": [],
      "source": [
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50000):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    if isinstance(sentence, str):\n",
        "        nlp = spacy.load('en')\n",
        "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "\n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
        "\n",
        "    src_mask = model.make_src_mask(src_tensor)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        enc_src = model.encoder(src_tensor, src_mask)\n",
        "\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "\n",
        "    for i in range(max_len):\n",
        "\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
        "\n",
        "        trg_mask = model.make_trg_mask(trg_tensor)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
        "\n",
        "        pred_token = output.argmax(2)[:,-1].item()\n",
        "\n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "\n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "\n",
        "    return trg_tokens[1:], attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIyQeFx-dMlK",
        "outputId": "dfbfae11-3d84-4a63-d12e-3a42a6879360"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicted trg sequence: \n",
            "[(63, 'utf-8'), (1, 'def'), (1, 'add'), (54, '('), (1, 'x'), (54, ','), (1, 'y'), (54, ')'), (54, ':'), (4, '\\n'), (5, '    '), (1, 'return'), (1, 'x'), (54, '+'), (1, 'y'), (4, ''), (6, ''), (0, ''), '<eos>']\n",
            "code: \n",
            " def add (x ,y ):\n",
            "    return x +y \n"
          ]
        }
      ],
      "source": [
        "src = \"write a function that adds two numbers\"\n",
        "src=src.split(\" \")\n",
        "translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg sequence: ')\n",
        "print(translation)\n",
        "print(\"code: \\n\", untokenize(translation[:-1]).decode('utf-8'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhIC2mgfv37B"
      },
      "source": [
        "# Giving random (non-datset) prompts to test our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_d2MUwHK62D",
        "outputId": "ec8b82b1-7a27-4b8f-9172-543d6d232795"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('/content/conversational-ai-model.pt'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vveLENmdLEE4"
      },
      "source": [
        "Function that translates an English src string to python code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hiYFFxnzj6Mn"
      },
      "outputs": [],
      "source": [
        "def eng_to_python(src):\n",
        "  src=src.split(\" \")\n",
        "  translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
        "\n",
        "  print(f'predicted trg: \\n')\n",
        "  print(untokenize(translation[:-1]).decode('utf-8'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TG3TsKgQWy4p"
      },
      "outputs": [],
      "source": [
        "SRC = Input\n",
        "TRG = Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuNEA7wzijhY",
        "outputId": "e11c0f0e-7299-419b-adf1-aa0201b39d03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicted trg: \n",
            "\n",
            "var_1 =[{1 :2 :3 ,4 :5 :3 ,8 :9 ,10 :1 },{1 :10 :12 },\n",
            "{'tsai':1 ,3 ,4 ,5 :5 }]\n",
            "var_2 =[5 ,6 ]\n",
            "print (var_2 )\n"
          ]
        }
      ],
      "source": [
        "src = \"program to sort a list of dictionaries by key\"\n",
        "\n",
        "eng_to_python(src)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHOL5t7SjVeh",
        "outputId": "173e1527-40db-4f0c-e641-3b7178a5a76e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicted trg: \n",
            "\n",
            "\n",
            "def append_lists (l1 :list ,l2 :list )->list :\n",
            "    return l1 .extend (l2 )\n"
          ]
        }
      ],
      "source": [
        "src = \"function to merge two lists\"\n",
        "\n",
        "eng_to_python(src)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FeOSKNqAWwW",
        "outputId": "ea42758a-8ce2-493f-bcfb-c047c822a8b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicted trg: \n",
            "\n",
            "\n",
            "def remove_item_dict (d ,var_1 ):\n",
            "    for var_2 in d :\n",
            "        if var_2 in d :\n",
            "            del d [var_2 ]\n",
            "    return d \n"
          ]
        }
      ],
      "source": [
        "src = \"program to iterate over dictionary\"\n",
        "\n",
        "eng_to_python(src)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oV_AN_X3AtNo",
        "outputId": "d5080b85-d9a4-4be0-ebda-c190c18e6bb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicted trg: \n",
            "\n",
            "\n",
            "def oddeven (num ):\n",
            "    if num %2 ==0 :\n",
            "        print ('even')\n",
            "    else :\n",
            "        print ('odd')\n"
          ]
        }
      ],
      "source": [
        "src = \"program to print even numbers\"\n",
        "\n",
        "eng_to_python(src)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tessB9dcBYxQ",
        "outputId": "a4a16197-ed95-4ce2-fc2e-98c0ba96886a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicted trg: \n",
            "\n",
            "\n",
            "var_1 =input (\"Enter a string! \")\n",
            "count =0 \n",
            "for var_2 in var_1 :\n",
            "    if var_2 .isdigit ():\n",
            "        count =count +1 \n",
            "    elif var_2 :\n",
            "        count +=1 \n",
            "    else :\n",
            "        count +=1 \n",
            "print (\"Total letters found : \",count )\n",
            "print (\"Total digits found : \",count )\n"
          ]
        }
      ],
      "source": [
        "src = \"program to input a string and count number of characters\"\n",
        "\n",
        "eng_to_python(src)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WqV2HQEKkEi"
      },
      "source": [
        "<hr>\n",
        "<hr>"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
